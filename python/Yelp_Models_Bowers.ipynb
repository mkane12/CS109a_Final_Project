{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer as Tfidf\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as dt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "from sklearn.decomposition import TruncatedSVD as SVD\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('json_2015.json')\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382418</th>\n",
       "      <td>lPONCVSGRrobKoZtZQh0Gw</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>I've been vaping for a while now and have trie...</td>\n",
       "      <td>0</td>\n",
       "      <td>UkASldEgm9snvR0LVfZm4w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445629</th>\n",
       "      <td>iUPJmJvHy9fVfRxsuwwdLQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Outstanding set up they have here. Food was br...</td>\n",
       "      <td>1</td>\n",
       "      <td>0QZ1jroPjmJbHtKeX-jk6g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436085</th>\n",
       "      <td>RIPnl1BAUaY2rSW8cPuQWQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-08-26</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>I get Star Wok when I am at work as I can't le...</td>\n",
       "      <td>0</td>\n",
       "      <td>f8PvRnAj7KYb8s-aPjRhtA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366946</th>\n",
       "      <td>8DKEWD2DaU6XlMNRN4QNlA</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-24</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Hek Yeah's brisket is where its at!\\n\\n It's m...</td>\n",
       "      <td>1</td>\n",
       "      <td>WOFZoOQrzYSLxJ6td6cecg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195840</th>\n",
       "      <td>d_QoB6QfsGVqSzB3cGO_tA</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>This place is pretty good when you want a pizz...</td>\n",
       "      <td>0</td>\n",
       "      <td>o19jYvtqRsI9LSO0we8ROg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  cool       date  funny  stars  \\\n",
       "382418  lPONCVSGRrobKoZtZQh0Gw     2 2015-07-31      1      5   \n",
       "445629  iUPJmJvHy9fVfRxsuwwdLQ     1 2015-08-31      1      4   \n",
       "436085  RIPnl1BAUaY2rSW8cPuQWQ     0 2015-08-26      1      4   \n",
       "366946  8DKEWD2DaU6XlMNRN4QNlA     0 2015-07-24      0      5   \n",
       "195840  d_QoB6QfsGVqSzB3cGO_tA     0 2015-04-25      0      3   \n",
       "\n",
       "                                                     text  useful  \\\n",
       "382418  I've been vaping for a while now and have trie...       0   \n",
       "445629  Outstanding set up they have here. Food was br...       1   \n",
       "436085  I get Star Wok when I am at work as I can't le...       0   \n",
       "366946  Hek Yeah's brisket is where its at!\\n\\n It's m...       1   \n",
       "195840  This place is pretty good when you want a pizz...       0   \n",
       "\n",
       "                       user_id  \n",
       "382418  UkASldEgm9snvR0LVfZm4w  \n",
       "445629  0QZ1jroPjmJbHtKeX-jk6g  \n",
       "436085  f8PvRnAj7KYb8s-aPjRhtA  \n",
       "366946  WOFZoOQrzYSLxJ6td6cecg  \n",
       "195840  o19jYvtqRsI9LSO0we8ROg  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start by drawing a 50,000 observation sample for the dataset to make parameter tuning reasonable â€“ the full dataset can take a very long time to run.\n",
    "\n",
    "I've also decided to take only the top 10,000 words in the vocabulary across reviews. Messing with this number seemed to make relatively little difference in accuracy (slight improvement over no limit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#standardize predictor variables\n",
    "\n",
    "def scorer_pos(estimator, X, y): #custom scoring functions to get positive and negative accuracy\n",
    "    y_pred = estimator.predict(X)\n",
    "    return np.mean(y_pred[y == 1] == y[y == 1])\n",
    "\n",
    "def scorer_neg(estimator, X, y):\n",
    "    estimator.fit(X, y)\n",
    "    y_pred = estimator.predict(X)\n",
    "    return np.mean(y_pred[y == 0] == y[y == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model(x, binary_y, model, title, coefs=False):\n",
    "    model.fit(x, binary_y)\n",
    "    y_pred = model.predict(x)\n",
    "    binary_y = np.array(binary_y)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(binary_y, y_pred).ravel() #from sklearn docs\n",
    "\n",
    "    print title\n",
    "    print confusion_matrix(binary_y, y_pred)\n",
    "\n",
    "    print \"False Positive Rate:\", fp/float(fp+tn)\n",
    "    print \"False Negative Rate:\", fn/float(fn+tp)\n",
    "    print \"True Positive Rate:\", tp/float(tp+fp)\n",
    "    print \"True Negative Rate:\", tn/float(tn+fn)\n",
    "    \n",
    "    print \"Positive Accuracy:\", cross_val_score(model, x, binary_y, n_jobs=-1, scoring=scorer_pos).mean()\n",
    "    print \"Negative Accuracy:\", cross_val_score(model, x, binary_y, n_jobs=-1, scoring=scorer_neg).mean()\n",
    "    print \"Cross Validated Accuracy on Sample:\", cross_val_score(model, x, binary_y, n_jobs=-1).mean()\n",
    "    print \"Train Set Accuracy on Sample:\", np.mean(y_pred == binary_y)\n",
    "    print\n",
    "    if coefs == True:\n",
    "        mydict = zip(model.coef_[0], vectorizer.get_feature_names())\n",
    "        words = sorted([(i[0], i[1].encode('utf-8')) for i in mydict], reverse=True, key=lambda x: x[0])\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # stem\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp = data.sample(50000) #draw samples\n",
    "samp.shape\n",
    "frac_useful = 1 - data['useful'].value_counts()[0] / float(data.shape[0])\n",
    "frac_funny = 1 - data['funny'].value_counts()[0] / float(data.shape[0])\n",
    "frac_cool = 1 - data['cool'].value_counts()[0] / float(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', \n",
    "                             binary=False, \n",
    "                             max_features=10000,\n",
    "                             analyzer='word',\n",
    "                             tokenizer=tokenize\n",
    "                            ) #using non-binary Count Vec.\n",
    "reviews = samp.text.values\n",
    "\n",
    "#tokenize words\n",
    "x = vectorizer.fit_transform(reviews)\n",
    "\n",
    "y_useful = [] #class observations according to whether they have at least one \"helpful\" vote\n",
    "y_cool = []\n",
    "y_funny = []\n",
    "\n",
    "\n",
    "for score in samp.useful.values:\n",
    "    i = 1 if score > 0 else 0\n",
    "    y_useful.append(i)\n",
    "\n",
    "for score in samp.cool.values:\n",
    "    i = 1 if score > 0 else 0\n",
    "    y_cool.append(i)\n",
    "\n",
    "for score in samp.funny.values:\n",
    "    i = 1 if score > 0 else 0\n",
    "    y_funny.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful\n",
      "[[22140  9002]\n",
      " [ 6655 12203]]\n",
      "False Positive Rate: 0.289063001734\n",
      "False Negative Rate: 0.352900625729\n",
      "True Positive Rate: 0.575477481726\n",
      "True Negative Rate: 0.768883486716\n",
      "Positive Accuracy: 0.56808781419\n",
      "Negative Accuracy: 0.73412118392\n",
      "Cross Validated Accuracy on Sample: 0.629859952903\n",
      "Train Set Accuracy on Sample: 0.68686\n",
      "\n",
      "Funny\n",
      "[[28419 12858]\n",
      " [ 2193  6530]]\n",
      "False Positive Rate: 0.311505196599\n",
      "False Negative Rate: 0.251404333372\n",
      "True Positive Rate: 0.336806271921\n",
      "True Negative Rate: 0.928361426891\n",
      "Positive Accuracy: 0.58936148685\n",
      "Negative Accuracy: 0.720861496717\n",
      "Cross Validated Accuracy on Sample: 0.654100021324\n",
      "Train Set Accuracy on Sample: 0.69898\n",
      "\n",
      "Cool\n",
      "[[26204 12752]\n",
      " [ 3150  7894]]\n",
      "False Positive Rate: 0.327343669781\n",
      "False Negative Rate: 0.285222745382\n",
      "True Positive Rate: 0.382350092028\n",
      "True Negative Rate: 0.892689241671\n",
      "Positive Accuracy: 0.582217048629\n",
      "Negative Accuracy: 0.702767218898\n",
      "Cross Validated Accuracy on Sample: 0.627839954011\n",
      "Train Set Accuracy on Sample: 0.68196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "u_tune = 0.03\n",
    "f_tune = 0.03\n",
    "c_tune = 0.03\n",
    "\n",
    "weights = {0:1/(1 - frac_useful + u_tune), 1:1/(frac_useful - u_tune)}\n",
    "log_model = LogReg(C=0.01, penalty='l2', class_weight=weights) #initialize logistic regression model\n",
    "\n",
    "rand = RandomForestClassifier(n_estimators=500, criterion='gini', \n",
    "                              max_features= 17, max_depth=15, class_weight='balanced_subsample')\n",
    "\n",
    "\n",
    "useful_words = test_model(x, y_useful, log_model, \"Useful\")\n",
    "funny_words = test_model(x, y_funny, \n",
    "                         log_model.set_params(class_weight={0:1/(1 - frac_funny + f_tune), 1:1/(frac_funny - f_tune)}), \"Funny\")\n",
    "cool_words = test_model(x, y_cool, \n",
    "                        log_model.set_params(class_weight={0:1/(1 - frac_cool + c_tune), 1:1/(frac_cool - c_tune)}), \"Cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"10 Coolest Words:\"\n",
    "for word in cool_words[:10]:\n",
    "    print word[1], word[0]\n",
    "\n",
    "print \"\\n10 Least Cool Words:\"\n",
    "for word in cool_words[-10:]:\n",
    "    print word[1], word[0]\n",
    "    \n",
    "print \"\\n10 Funniest Words:\"\n",
    "for word in funny_words[:10]:\n",
    "    print word[1], word[0]\n",
    "\n",
    "print \"\\n10 Least Funny Words:\"\n",
    "for word in funny_words[-10:]:\n",
    "    print word[1], word[0]\n",
    "    \n",
    "print \"\\n10 Most Useful Words:\"\n",
    "for word in useful_words[:10]:\n",
    "    print word[1], word[0]\n",
    "\n",
    "print \"\\n10 Least Useful Words:\"\n",
    "for word in useful_words[-10:]:\n",
    "    print word[1], word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful\n",
      "[[24406  6736]\n",
      " [ 8607 10251]]\n",
      "False Positive Rate: 0.21629953118\n",
      "False Negative Rate: 0.456411072224\n",
      "True Positive Rate: 0.603461470536\n",
      "True Negative Rate: 0.739284524278\n",
      "Positive Accuracy: 0.487061194188\n",
      "Negative Accuracy: 0.794875048699\n",
      "Cross Validated Accuracy on Sample: 0.652779944521\n",
      "Train Set Accuracy on Sample: 0.69314\n",
      "\n",
      "Funny\n",
      "[[32815  8462]\n",
      " [ 3510  5213]]\n",
      "False Positive Rate: 0.205005208712\n",
      "False Negative Rate: 0.402384500745\n",
      "True Positive Rate: 0.381206581353\n",
      "True Negative Rate: 0.903372333104\n",
      "Positive Accuracy: 0.476441827163\n",
      "Negative Accuracy: 0.810863192577\n",
      "Cross Validated Accuracy on Sample: 0.726599962181\n",
      "Train Set Accuracy on Sample: 0.76056\n",
      "\n",
      "Cool\n",
      "[[30468  8488]\n",
      " [ 4761  6283]]\n",
      "False Positive Rate: 0.217886846699\n",
      "False Negative Rate: 0.431093806592\n",
      "True Positive Rate: 0.42536050369\n",
      "True Negative Rate: 0.86485565869\n",
      "Positive Accuracy: 0.474556500113\n",
      "Negative Accuracy: 0.797001782851\n",
      "Cross Validated Accuracy on Sample: 0.695439996626\n",
      "Train Set Accuracy on Sample: 0.73502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "u_tune = 0.0\n",
    "f_tune = 0.0\n",
    "c_tune = 0.0\n",
    "\n",
    "weights = {0:1/(1 - frac_useful + u_tune), 1:1/(frac_useful - u_tune)}\n",
    "svm = LinearSVC(C=0.001, penalty='l2', class_weight='balanced') #initialize logistic regression model\n",
    "\n",
    "rand = RandomForestClassifier(n_estimators=500, criterion='gini', \n",
    "                              max_features= 17, max_depth=15, class_weight='balanced_subsample')\n",
    "\n",
    "\n",
    "useful_words = test_model(x, y_useful, svm, \"Useful\")\n",
    "funny_words = test_model(x, y_funny, \n",
    "                         svm, \"Funny\")\n",
    "cool_words = test_model(x, y_cool, \n",
    "                        svm, \"Cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
