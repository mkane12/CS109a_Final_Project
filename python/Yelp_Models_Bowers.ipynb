{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer as Tfidf\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as dt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split as sk_split\n",
    "from sklearn.decomposition import TruncatedSVD as SVD\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_json('json_2015.json')\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49452</th>\n",
       "      <td>b6N1f3rTZUbUom70SO55JQ</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Exactly what was needed on a freezing Montreal...</td>\n",
       "      <td>1</td>\n",
       "      <td>pSKUMl2e4e5fMPAeOZBDQQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610067</th>\n",
       "      <td>nLLs9fIiWw6WDku3_2NVVA</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-11-28</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Been coming here since 2006!  Love you Miss An...</td>\n",
       "      <td>1</td>\n",
       "      <td>w4ShwIy38e0EjhrjVZ2M2Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367089</th>\n",
       "      <td>kePxkm183BDiOiDcsjgAhg</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-24</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Happy to have found a great pizza spot near ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>DA5Voj58AOt_tyzDAKTIvw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333714</th>\n",
       "      <td>K8dQr_82-DMpDudEv8PDmw</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Five of us went to lunch at the location on Ea...</td>\n",
       "      <td>0</td>\n",
       "      <td>htkgFj7DCtLjQjL9xIBGrA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577965</th>\n",
       "      <td>dVAurLD1bBIi9IvuMFoL5g</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-11-10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Food is delicious and the waitress was friendl...</td>\n",
       "      <td>0</td>\n",
       "      <td>2GLSTaqJn_Vd6sOPOXQtLQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   business_id  cool       date  funny  stars  \\\n",
       "49452   b6N1f3rTZUbUom70SO55JQ     1 2015-01-31      1      4   \n",
       "610067  nLLs9fIiWw6WDku3_2NVVA     0 2015-11-28      0      4   \n",
       "367089  kePxkm183BDiOiDcsjgAhg     0 2015-07-24      0      4   \n",
       "333714  K8dQr_82-DMpDudEv8PDmw     1 2015-07-08      2      2   \n",
       "577965  dVAurLD1bBIi9IvuMFoL5g     0 2015-11-10      0      5   \n",
       "\n",
       "                                                     text  useful  \\\n",
       "49452   Exactly what was needed on a freezing Montreal...       1   \n",
       "610067  Been coming here since 2006!  Love you Miss An...       1   \n",
       "367089  Happy to have found a great pizza spot near ou...       0   \n",
       "333714  Five of us went to lunch at the location on Ea...       0   \n",
       "577965  Food is delicious and the waitress was friendl...       0   \n",
       "\n",
       "                       user_id  \n",
       "49452   pSKUMl2e4e5fMPAeOZBDQQ  \n",
       "610067  w4ShwIy38e0EjhrjVZ2M2Q  \n",
       "367089  DA5Voj58AOt_tyzDAKTIvw  \n",
       "333714  htkgFj7DCtLjQjL9xIBGrA  \n",
       "577965  2GLSTaqJn_Vd6sOPOXQtLQ  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#standardize predictor variables\n",
    "\n",
    "def scorer_pos(estimator, X, y): #custom scoring functions to get positive and negative accuracy\n",
    "    y_pred = estimator.predict(X)\n",
    "    return np.float(np.mean(y_pred[y == 1] == y[y == 1]))\n",
    "\n",
    "def scorer_neg(estimator, X, y):\n",
    "    estimator.fit(X, y)\n",
    "    y_pred = estimator.predict(X)\n",
    "    return np.float(np.mean(y_pred[y == 0] == y[y == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model(x, binary_y, model, title, coefs=False):\n",
    "    model.fit(x, binary_y)\n",
    "    y_pred = model.predict(x)\n",
    "    binary_y = np.array(binary_y)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(binary_y, y_pred).ravel() #from sklearn docs\n",
    "\n",
    "    print title\n",
    "    print confusion_matrix(binary_y, y_pred)\n",
    "\n",
    "    print \"False Positive Rate:\", fp/float(fp+tn)\n",
    "    print \"False Negative Rate:\", fn/float(fn+tp)\n",
    "    print \"True Positive Rate:\", tp/float(tp+fp)\n",
    "    print \"True Negative Rate:\", tn/float(tn+fn)\n",
    "    \n",
    "    print \"Positive Accuracy:\", cross_val_score(model, x, binary_y, n_jobs=-1, scoring=scorer_pos).mean()\n",
    "    print \"Negative Accuracy:\", cross_val_score(model, x, binary_y, n_jobs=-1, scoring=scorer_neg).mean()\n",
    "    print \"Cross Validated Accuracy on Sample:\", cross_val_score(model, x, binary_y, n_jobs=-1).mean()\n",
    "    print \"Cross Validated AUC on Sample:\", cross_val_score(model, x, binary_y, n_jobs=-1, scoring='roc_auc').mean()\n",
    "    print \"Train Set Accuracy on Sample:\", np.mean(y_pred == binary_y)\n",
    "    print\n",
    "    if coefs == True:\n",
    "        mydict = zip(model.coef_[0], vectorizer.get_feature_names())\n",
    "        words = sorted([(i[0], i[1].encode('utf-8')) for i in mydict], reverse=True, key=lambda x: x[0])\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samp = data.sample(100000) #draw samples\n",
    "\n",
    "#lengths = [len(i[1]['text']) for i in samp.iterrows()]\n",
    "\n",
    "samp.shape\n",
    "frac_useful = 1 - data['useful'].value_counts()[0] / float(data.shape[0])\n",
    "frac_funny = 1 - data['funny'].value_counts()[0] / float(data.shape[0])\n",
    "frac_cool = 1 - data['cool'].value_counts()[0] / float(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "                             binary=False, \n",
    "                             max_features=10000,\n",
    "                             analyzer='word',\n",
    "                             #tokenizer=tokenize,\n",
    "                             sublinear_tf=False\n",
    "                            ) #using non-binary Count Vec.\n",
    "reviews = samp.text.values\n",
    "\n",
    "#tokenize words\n",
    "x = vectorizer.fit_transform(reviews)\n",
    "\n",
    "y_useful = [] #class observations according to whether they have at least one \"helpful\" vote\n",
    "y_cool = []\n",
    "y_funny = []\n",
    "\n",
    "\n",
    "for score in samp.useful.values:\n",
    "    i = 1 if score > 0 else 0\n",
    "    y_useful.append(i)\n",
    "\n",
    "for score in samp.cool.values:\n",
    "    i = 1 if score > 0 else 0\n",
    "    y_cool.append(i)\n",
    "\n",
    "for score in samp.funny.values:\n",
    "    i = 1 if score > 0 else 0\n",
    "    y_funny.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful\n",
      "[[39023 23274]\n",
      " [13960 23743]]\n",
      "False Positive Rate: 0.3735974445\n",
      "False Negative Rate: 0.370262313344\n",
      "True Positive Rate: 0.504987557692\n",
      "True Negative Rate: 0.736519260895\n",
      "Positive Accuracy: 0.618200042088\n",
      "Negative Accuracy: 0.618729688797\n",
      "Cross Validated Accuracy on Sample: 0.614509993491\n",
      "Cross Validated AUC on Sample: 0.65683052466\n",
      "Train Set Accuracy on Sample: 0.62766\n",
      "\n",
      "Funny\n",
      "[[52218 30371]\n",
      " [ 5672 11739]]\n",
      "False Positive Rate: 0.367736623521\n",
      "False Negative Rate: 0.32577106427\n",
      "True Positive Rate: 0.278769888388\n",
      "True Negative Rate: 0.902021074452\n",
      "Positive Accuracy: 0.650622827162\n",
      "Negative Accuracy: 0.629563256722\n",
      "Cross Validated Accuracy on Sample: 0.628330010503\n",
      "Cross Validated AUC on Sample: 0.684328639826\n",
      "Train Set Accuracy on Sample: 0.63957\n",
      "\n",
      "Cool\n",
      "[[52379 25942]\n",
      " [ 8849 12830]]\n",
      "False Positive Rate: 0.331226618659\n",
      "False Negative Rate: 0.408183034273\n",
      "True Positive Rate: 0.330908903332\n",
      "True Negative Rate: 0.855474619455\n",
      "Positive Accuracy: 0.562618393702\n",
      "Negative Accuracy: 0.677225775973\n",
      "Cross Validated Accuracy on Sample: 0.639820024528\n",
      "Cross Validated AUC on Sample: 0.653782421129\n",
      "Train Set Accuracy on Sample: 0.65209\n",
      "\n"
     ]
    }
   ],
   "source": [
    "u_tune = 0.00\n",
    "f_tune = 0.00\n",
    "c_tune = 0.00\n",
    "\n",
    "weights = {0:1/(1 - frac_useful + u_tune), 1:1/(frac_useful - u_tune)}\n",
    "log_model = LogReg(C=0.01, penalty='l2', class_weight=weights) #initialize logistic regression model\n",
    "\n",
    "rand = RandomForestClassifier(n_estimators=300, criterion='gini', \n",
    "                              max_features= 17, max_depth=5, class_weight='balanced')\n",
    "\n",
    "\n",
    "\n",
    "useful_words = test_model(x, y_useful, \n",
    "                          log_model,\n",
    "                          \"Useful\",\n",
    "                          coefs=True)\n",
    "funny_words = test_model(x, y_funny, \n",
    "                         log_model.set_params(class_weight={0:1/(1 - frac_funny + f_tune), 1:1/(frac_funny - f_tune)}), \n",
    "                         \"Funny\",\n",
    "                          coefs=True)\n",
    "cool_words = test_model(x, y_cool, \n",
    "                        log_model.set_params(class_weight={0:1/(1 - frac_cool + c_tune), 1:1/(frac_cool - c_tune)}),\n",
    "                        #rand,\n",
    "                        \"Cool\",\n",
    "                          coefs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Coolest Words:\n",
      "like 0.777424522012\n",
      "located 0.708692141904\n",
      "sweet 0.596027333682\n",
      "pretty 0.587713623414\n",
      "just 0.58669470053\n",
      "really 0.582469561931\n",
      "parking 0.547471412001\n",
      "chocolate 0.535126172207\n",
      "super 0.527952364645\n",
      "sauce 0.516050598666\n",
      "\n",
      "10 Least Cool Words:\n",
      "went -0.345816467649\n",
      "recommend -0.365388522898\n",
      "horrible -0.390631721062\n",
      "manager -0.403196833487\n",
      "terrible -0.416126345079\n",
      "worst -0.440876800444\n",
      "rude -0.443960801587\n",
      "great -0.444499375893\n",
      "service -0.497695247434\n",
      "food -0.558533053578\n",
      "\n",
      "10 Funniest Words:\n",
      "like 1.13839855057\n",
      "just 0.813520830243\n",
      "don 0.808764548389\n",
      "didn 0.646168441247\n",
      "located 0.619280782323\n",
      "know 0.616936449465\n",
      "yes 0.612434737306\n",
      "pretty 0.585773292773\n",
      "sauce 0.572446408989\n",
      "review 0.560262493674\n",
      "\n",
      "10 Least Funny Words:\n",
      "friendly -0.614596408423\n",
      "delicious -0.614707047056\n",
      "good -0.628918101188\n",
      "amazing -0.644397665231\n",
      "atmosphere -0.653712539408\n",
      "awesome -0.661020120554\n",
      "excellent -0.801377542046\n",
      "best -0.809623901391\n",
      "recommend -0.952156412581\n",
      "great -1.72489232167\n",
      "\n",
      "10 Most Useful Words:\n",
      "like 0.821068724132\n",
      "just 0.749092849545\n",
      "don 0.559112510733\n",
      "didn 0.530764734316\n",
      "review 0.507417830527\n",
      "told 0.494244007668\n",
      "pretty 0.483290202456\n",
      "decided 0.478827007759\n",
      "yelp 0.461538073363\n",
      "sauce 0.458371835041\n",
      "\n",
      "10 Least Useful Words:\n",
      "awesome -0.421435727157\n",
      "breakfast -0.428924744215\n",
      "service -0.452324101023\n",
      "recommend -0.459115961944\n",
      "amazing -0.477220236994\n",
      "excellent -0.57435809856\n",
      "best -0.598379804062\n",
      "food -0.709794203304\n",
      "good -0.729206665463\n",
      "great -1.26910382199\n"
     ]
    }
   ],
   "source": [
    "print \"10 Coolest Words:\"\n",
    "for word in cool_words[:10]:\n",
    "    print word[1], word[0]\n",
    "\n",
    "print \"\\n10 Least Cool Words:\"\n",
    "for word in cool_words[-10:]:\n",
    "    print word[1], word[0]\n",
    "    \n",
    "print \"\\n10 Funniest Words:\"\n",
    "for word in funny_words[:10]:\n",
    "    print word[1], word[0]\n",
    "\n",
    "print \"\\n10 Least Funny Words:\"\n",
    "for word in funny_words[-10:]:\n",
    "    print word[1], word[0]\n",
    "    \n",
    "print \"\\n10 Most Useful Words:\"\n",
    "for word in useful_words[:10]:\n",
    "    print word[1], word[0]\n",
    "\n",
    "print \"\\n10 Least Useful Words:\"\n",
    "for word in useful_words[-10:]:\n",
    "    print word[1], word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Useful\n",
      "[[166388  82731]\n",
      " [ 58412  92469]]\n",
      "False Positive Rate: 0.332094300314\n",
      "False Negative Rate: 0.387139533805\n",
      "True Positive Rate: 0.52779109589\n",
      "True Negative Rate: 0.740160142349\n",
      "Positive Accuracy: 0.599452569747\n",
      "Negative Accuracy: 0.661314481825\n",
      "Cross Validated Accuracy on Sample: 0.634405008157\n",
      "Cross Validated AUC on Sample: 0.673775543874\n",
      "Train Set Accuracy on Sample: 0.6471425\n",
      "\n",
      "Funny\n",
      "[[224376 106569]\n",
      " [ 23641  45414]]\n",
      "False Positive Rate: 0.322014231972\n",
      "False Negative Rate: 0.342350300485\n",
      "True Positive Rate: 0.298809735299\n",
      "True Negative Rate: 0.904679921134\n",
      "Positive Accuracy: 0.628861110506\n",
      "Negative Accuracy: 0.672997023675\n",
      "Cross Validated Accuracy on Sample: 0.662530004008\n",
      "Cross Validated AUC on Sample: 0.70180118236\n",
      "Train Set Accuracy on Sample: 0.674475\n",
      "\n",
      "Cool\n",
      "[[214325  98403]\n",
      " [ 34632  52640]]\n",
      "False Positive Rate: 0.314660024046\n",
      "False Negative Rate: 0.396828306903\n",
      "True Positive Rate: 0.348510026946\n",
      "True Negative Rate: 0.860891639922\n",
      "Positive Accuracy: 0.577413101408\n",
      "Negative Accuracy: 0.682833003663\n",
      "Cross Validated Accuracy on Sample: 0.654847498833\n",
      "Cross Validated AUC on Sample: 0.674034342037\n",
      "Train Set Accuracy on Sample: 0.6674125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "u_tune = 0.0\n",
    "f_tune = 0.0\n",
    "c_tune = 0.0\n",
    "\n",
    "weights = {0:1/(1 - frac_useful + u_tune), 1:1/(frac_useful - u_tune)}\n",
    "svm = LinearSVC(C=0.001, penalty='l2', class_weight='balanced') #initialize logistic regression model\n",
    "\n",
    "rand = RandomForestClassifier(n_estimators=500, criterion='gini', \n",
    "                              max_features= 17, max_depth=15, class_weight='balanced_subsample')\n",
    "\n",
    "\n",
    "useful_words = test_model(x, y_useful, svm, \"Useful\")\n",
    "funny_words = test_model(x, y_funny, \n",
    "                         svm, \"Funny\")\n",
    "cool_words = test_model(x, y_cool, \n",
    "                        svm, \"Cool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
